{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa0c13d-3d19-47ee-8315-8d3554014eb6",
   "metadata": {},
   "source": [
    "1. importing the required libarires\n",
    "2. Normalization of input data. purpose: Neural networks train faster and converge better when input values are centered (mean â‰ˆ 0) and scaled.Helps with gradient descent stability.\n",
    "3. loading train data from pytorch datasets train and test (data augumentation (not needed here))\n",
    "4. load to dataloader, batches, shuffles, processes\n",
    "5. Define classes\n",
    "6. build neural network\n",
    "7. define loss function\n",
    "8. run epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbf55a2-bb74-45d4-b132-1ff3a67a6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch torchvision torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29cd0447-5b54-4c69-a82b-77f1f3e4a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #implementing optimization algorithms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a349fbe0-bbb7-435c-a045-7c253cbbbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                               ])\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c64ce8f-2321-41ce-8a18-ffec8ae17dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root is where data will be downloaded. \"data\" is the folder, if not will be created. train True means load the training data. applies transofrmation as mentioned in step2\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True,download=True,transform=transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cb9c21-0087-4949-920a-654eaf64ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 4 indicates it processes 4 images at once, shuffle True means it shuffles at every epoch to avoid order based learning, num workers are subprocesses, you can use 0 also\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=4,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df092cd1-1085-43de-b0c3-f23581063390",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset=torchvision.datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db00913e-8cfd-4838-8edd-9a0ae77c3933",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader= torch.utils.data.DataLoader(testset,batch_size=4,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b585a9-5b3d-4397-8642-e816ad2e6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define classes\n",
    "classes=('plane','car','bird','cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e31f5b-d625-4a92-bd82-76c4325d275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): #inherits nn.Module attributes\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__() # calls parent class initialization \n",
    "        self.conv1=nn.Conv2d(3,6,5) # 3 input channels , out channels, kenel size, strides, padding, dilation\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(torch.relu(self.conv1(x)))\n",
    "        x=self.pool(torch.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)\n",
    "        x=torch.relu(self.fc1(x))\n",
    "        x=torch.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1fb5dd-2c2e-426c-907b-bcd1986f4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf68aa1-e511-4ce3-af3c-6fbb4ae05090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b75fcb70-16af-4ab9-af6a-b0ab1e98f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60526273-9e79-49c7-93f7-6a8ae7e03aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 2.186\n",
      "[1, 4000] loss: 1.852\n",
      "[1, 6000] loss: 1.664\n",
      "[1, 8000] loss: 1.581\n",
      "[1,10000] loss: 1.532\n",
      "[1,12000] loss: 1.468\n",
      "[2, 2000] loss: 1.408\n",
      "[2, 4000] loss: 1.382\n",
      "[2, 6000] loss: 1.390\n",
      "[2, 8000] loss: 1.357\n",
      "[2,10000] loss: 1.319\n",
      "[2,12000] loss: 1.276\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss=0.0\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels=data\n",
    "        optimizer.zero_grad()\n",
    "        outputs=net(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss +=loss.item()\n",
    "        if i%2000 ==1999:\n",
    "            print ('[%d,%5d] loss: %.3f' %\n",
    "                  (epoch+1,i+1,running_loss/2000))\n",
    "            running_loss=0.0\n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab5644bc-9de6-43ed-a7f6-f9252779c1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a7831f0-80e4-474d-b392-ea3579ec4a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data\n",
    "        outputs=net(images)\n",
    "        _,predicted= torch.max(outputs.data,1)\n",
    "        total +=labels.size(0)\n",
    "        correct +=(predicted ==labels).sum().item()\n",
    "print(\"accuracy of the network on the 10000 test images: %d %%\" %(100*correct/total))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e337a12-3591-4f6c-9642-32b32821b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2000] loss: 1.212\n",
      "[1, 4000] loss: 1.236\n",
      "[1, 6000] loss: 1.208\n",
      "[1, 8000] loss: 1.188\n",
      "[1,10000] loss: 1.208\n",
      "[1,12000] loss: 1.162\n",
      "[2, 2000] loss: 1.119\n",
      "[2, 4000] loss: 1.113\n",
      "[2, 6000] loss: 1.113\n",
      "[2, 8000] loss: 1.126\n",
      "[2,10000] loss: 1.086\n",
      "[2,12000] loss: 1.108\n",
      "[3, 2000] loss: 1.020\n",
      "[3, 4000] loss: 1.025\n",
      "[3, 6000] loss: 1.041\n",
      "[3, 8000] loss: 1.045\n",
      "[3,10000] loss: 1.063\n",
      "[3,12000] loss: 1.043\n",
      "[4, 2000] loss: 0.948\n",
      "[4, 4000] loss: 0.994\n",
      "[4, 6000] loss: 0.971\n",
      "[4, 8000] loss: 0.989\n",
      "[4,10000] loss: 0.991\n",
      "[4,12000] loss: 1.008\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "#running 4 epochs\n",
    "for epoch in range(4):\n",
    "    running_loss=0.0\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels=data\n",
    "        optimizer.zero_grad()\n",
    "        outputs=net(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss +=loss.item()\n",
    "        if i%2000 ==1999:\n",
    "            print ('[%d,%5d] loss: %.3f' %\n",
    "                  (epoch+1,i+1,running_loss/2000))\n",
    "            running_loss=0.0\n",
    "print(\"finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24d3af4-a53f-4e69-b124-75d21626a0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images,labels = data\n",
    "        outputs=net(images)\n",
    "        _,predicted= torch.max(outputs.data,1)\n",
    "        total +=labels.size(0)\n",
    "        correct +=(predicted ==labels).sum().item()\n",
    "print(\"accuracy of the network on the 10000 test images: %d %%\" %(100*correct/total))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e128a7-e97b-481d-9638-329d6ba77665",
   "metadata": {},
   "source": [
    "The last two steps can be repeated with varying numbers of epochs and batch sizes (depending on memory), allowing for experimentation and fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
